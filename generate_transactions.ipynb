{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import pickle\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm import trange, tqdm\n",
        "import os\n",
        "\n",
        "\n",
        "random.seed(42)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1748535822812
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ver = str(random.randint(10, 500))\n",
        "csv_file_path = './csv_files/' + ver\n",
        "ver = '_'+ver+'_'\n",
        "print(ver)\n",
        "# Create a single directory\n",
        "os.makedirs(csv_file_path, exist_ok=True)  # Will not raise an error if it already exists\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "_337_\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1748535823083
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_taxpayers_df = pd.read_csv('all_taxpayers.csv')\n",
        "all_taxpayers_df.head()\n",
        "print(len(all_taxpayers_df))\n",
        "#load sector details\n",
        "\n",
        "with open('sector_details.pkl', 'rb') as f:\n",
        "    sector_details = pickle.load(f)\n",
        "\n",
        "n_transactions = 200000\n",
        "invalid_transactions = set()\n",
        "undeclared_ratio=0.05\n",
        "n_declared = int(n_transactions * (1 - undeclared_ratio))\n",
        "n_undeclared = n_transactions - n_declared"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "10100\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1748535823288
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "allowed_sector_transactions = allowed_links = {\n",
        "    'Retail': ['Wholesale Trade', 'Manufacturing', 'Agriculture', 'Transportation & Logistics', 'ICT', 'Finance'],\n",
        "    'Manufacturing': ['Agriculture', 'Mining & Quarrying', 'Energy', 'Transportation & Logistics', 'Wholesale Trade', 'Construction'],\n",
        "    'Agriculture': ['Manufacturing', 'Wholesale Trade', 'Retail', 'Water & Sanitation', 'Finance'],\n",
        "    'Construction': ['Manufacturing', 'Wholesale Trade', 'Energy', 'Transportation & Logistics', 'Finance', 'Legal & Professional Services'],\n",
        "    'ICT': ['Finance', 'Telecommunications', 'Education', 'Healthcare', 'Legal & Professional Services', 'Retail', 'Entertainment & Media'],\n",
        "    'Finance': ['All'],  # Often connects to all sectors\n",
        "    'Hospitality': ['Agriculture', 'Wholesale Trade', 'Retail', 'Transportation & Logistics', 'Entertainment & Media'],\n",
        "    'Healthcare': ['Pharmaceuticals', 'Manufacturing', 'ICT', 'Education', 'Energy', 'Waste Management'],\n",
        "    'Education': ['ICT', 'Finance', 'Publishing', 'Retail', 'Public Administration'],\n",
        "    'Real Estate': ['Construction', 'Finance', 'Legal & Professional Services', 'Public Administration'],\n",
        "    'Transportation & Logistics': ['Wholesale Trade', 'Retail', 'Manufacturing', 'Energy', 'Agriculture', 'Mining & Quarrying'],\n",
        "    'Telecommunications': ['ICT', 'Finance', 'Education', 'Entertainment & Media'],\n",
        "    'Energy': ['Manufacturing', 'Mining & Quarrying', 'Construction', 'Transportation & Logistics', 'Water & Sanitation'],\n",
        "    'Legal & Professional Services': ['Finance', 'Real Estate', 'Construction', 'Public Administration', 'Healthcare'],\n",
        "    'Mining & Quarrying': ['Manufacturing', 'Construction', 'Energy', 'Transportation & Logistics'],\n",
        "    'Entertainment & Media': ['Retail', 'ICT', 'Arts & Culture', 'Telecommunications', 'Public Administration'],\n",
        "    'Public Administration': ['All'],  # Purchases from many sectors\n",
        "    'Water & Sanitation': ['Construction', 'Agriculture', 'Public Administration', 'Healthcare'],\n",
        "    'Waste Management': ['Healthcare', 'Construction', 'Public Administration', 'Water & Sanitation'],\n",
        "    'Security Services': ['Retail', 'Finance', 'Public Administration', 'Real Estate', 'Healthcare'],\n",
        "    'Wholesale Trade': ['Manufacturing', 'Agriculture', 'Retail', 'Transportation & Logistics'],\n",
        "    'Arts & Culture': ['Education', 'Entertainment & Media', 'Retail', 'Public Administration'],\n",
        "    'Transportation': ['Retail', 'Wholesale Trade', 'Agriculture', 'Construction', 'Healthcare']\n",
        "}\n",
        "\n",
        "locations = [\n",
        "    'Nairobi', 'Mombasa', 'Kisumu', 'Eldoret', 'Nakuru', 'Thika', 'Machakos',\n",
        "    'Kericho', 'Nyeri', 'Garissa', 'Meru', 'Kitale'\n",
        "]\n",
        "\n",
        "def is_valid_transaction(seller_sector, buyer_sector):\n",
        "    allowed = allowed_links.get(seller_sector, [])\n",
        "    return buyer_sector in allowed or 'All' in allowed or random.random() < 0.05  # 5% noise\n",
        "\n",
        "\n",
        "# === Generate VAT Transactions ===\n",
        "\n",
        "invoice_statuses = ['Paid', 'Pending', 'Cancelled', 'Disputed']\n",
        "payment_methods = ['Bank Transfer', 'Mobile Money', 'Cash', 'Cheque', 'Credit']\n",
        "\n",
        "existing_pairs = []\n",
        "pair_reuse_probability = 0.3  # 30% of transactions will reuse a pair\n",
        "\n",
        "transactions = []\n",
        "\n",
        "#KNBS’s Economic Survey (2024, 2023) offers seasonal insights across agriculture, trade, tourism, construction, and more \n",
        "#Kenya National Bureau of Statistics (KNBS) – Sectoral GDP by Quarter \n",
        "\n",
        "sector_burst_weights = {\n",
        "    'Retail': [0.12, 0.07, 0.06, 0.06, 0.06, 0.10, 0.05, 0.05, 0.06, 0.08, 0.12, 0.17],  # Jan, Jun, Nov-Dec\n",
        "    'Agriculture': [0.05, 0.05, 0.10, 0.10, 0.10, 0.05, 0.05, 0.05, 0.07, 0.13, 0.12, 0.08],  # Mar-May, Oct-Nov\n",
        "    'Hospitality': [0.08, 0.06, 0.06, 0.12, 0.07, 0.07, 0.07, 0.12, 0.06, 0.06, 0.06, 0.17],  # Apr, Aug, Dec\n",
        "    'Transport & Logistics': [0.06, 0.06, 0.06, 0.12, 0.08, 0.06, 0.06, 0.12, 0.06, 0.06, 0.06, 0.16],  # Apr, Aug, Dec\n",
        "    'Construction': [0.10, 0.10, 0.10, 0.06, 0.06, 0.06, 0.10, 0.10, 0.10, 0.05, 0.04, 0.03],  # Jan-Mar, Jul-Sep\n",
        "    \n",
        "    # Additions below\n",
        "    'Entertainment & Media': [0.10, 0.06, 0.05, 0.08, 0.08, 0.06, 0.06, 0.08, 0.06, 0.08, 0.10, 0.19],  # Peaks during school holidays, Dec\n",
        "    'Energy': [0.08, 0.08, 0.08, 0.09, 0.09, 0.08, 0.08, 0.08, 0.08, 0.09, 0.09, 0.08],  # Relatively stable, slight demand spikes in Apr, Oct\n",
        "    'Real Estate': [0.09, 0.09, 0.09, 0.07, 0.07, 0.07, 0.10, 0.10, 0.10, 0.07, 0.08, 0.07],  # Activity picks up in Jan-Mar, Jul-Sep\n",
        "    'Other': [0.05] * 12  # Default: uniform, no specific seasonal peaks\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "# Function to sample date with seasonality and burst variations\n",
        "def sample_seasonal_date(sector):\n",
        "    # Get the sector's seasonal burst weights\n",
        "    monthly_weights = sector_burst_weights.get(sector, sector_burst_weights['Other'])\n",
        "\n",
        "    # Choose month with seasonal probability\n",
        "    month = random.choices(range(12), weights=monthly_weights)[0]\n",
        "\n",
        "    # Optionally introduce bursts during specific weeks for certain sectors\n",
        "    burst_weeks = [10, 25, 27, 33, 48, 50]  # Defined burst weeks\n",
        "    burst_probability = 0.1  # 10% chance for a burst event\n",
        "\n",
        "    if random.random() < burst_probability:\n",
        "        week = random.choice(burst_weeks)\n",
        "        weekday = random.randint(0, 6)  # Random day in the week\n",
        "        date = datetime.strptime(f'2022-W{week:02d}-{weekday}', \"%Y-W%W-%w\")\n",
        "    else:\n",
        "        # Sample a date based on monthly weights\n",
        "        day = random.randint(1, 28)  # Safe for all months\n",
        "        date = datetime(2022, month + 1, day)\n",
        "    \n",
        "    return date\n",
        "\n",
        "\n",
        "#generate a valid transaction\n",
        "def generate_transaction(seller_id, buyer_id, declared = 1):\n",
        "    transaction = {}\n",
        "    goods_list = sector_details.get(seller['economic_sector'], {}).get('outputs', ['General Item'])\n",
        "    description = random.choice(goods_list)\n",
        "\n",
        "    sales_amount = round(random.uniform(500, 100000), 2)\n",
        "    invoice_date = sample_seasonal_date(seller['economic_sector'])\n",
        "    invoice_status = random.choices(invoice_statuses, weights=[0.7, 0.2, 0.05, 0.05])[0]\n",
        "    payment_method = random.choice(payment_methods)\n",
        "\n",
        "    transaction = {\n",
        "    'seller_id': seller['taxpayer_id'],\n",
        "    'buyer_id': buyer['taxpayer_id'],\n",
        "    'description_of_goods': description,\n",
        "    'sales_amount': sales_amount,\n",
        "    'invoice_date': invoice_date,\n",
        "    'invoice_status': invoice_status,\n",
        "    'payment_method': payment_method,\n",
        "    'location': seller['location'],\n",
        "    'economic_sector': seller['economic_sector'],\n",
        "    'buyer_size_category': buyer['size_category'],\n",
        "    'seller_size_category': seller['size_category'],\n",
        "    'declared' : declared\n",
        "}\n",
        "\n",
        "    return transaction"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1748535823511
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#generate \n",
        "\n",
        "# # Function to simulate declared transactions\n",
        "# def simulate_transactions(taxpayers, n_transactions=10000, undeclared_ratio=0.05):\n",
        "buyers = all_taxpayers_df.copy()\n",
        "sellers = all_taxpayers_df.copy()\n",
        "\n",
        "power_law_transactions = []\n",
        "high_degree_buyers = buyers.nlargest(100, 'size')['taxpayer_id'].tolist()\n",
        "\n",
        "\n",
        "\n",
        "for _ in trange(n_declared):\n",
        "    # Power-law selection: buyers are skewed toward large firms\n",
        "    # Preselect a small number of dominant buyers\n",
        "    buyer_id = random.choice(high_degree_buyers)\n",
        "    buyer = buyers[buyers['taxpayer_id'] == buyer_id].iloc[0]\n",
        "    seller = sellers.sample(weights=sellers['norm_size']).iloc[0]\n",
        "\n",
        "    # Prevent self-transactions\n",
        "    if seller['taxpayer_id'] == buyer['taxpayer_id']:\n",
        "        continue\n",
        "\n",
        "    if (seller['taxpayer_id'], buyer['taxpayer_id']) in invalid_transactions:\n",
        "        continue\n",
        "\n",
        "    elif not is_valid_transaction(seller['economic_sector'], seller['economic_sector']):\n",
        "        invalid_transactions.add((seller['taxpayer_id'], buyer['taxpayer_id']))\n",
        "        continue\n",
        "\n",
        "    power_law_transactions.append(\n",
        "        generate_transaction(seller['taxpayer_id'], buyer['taxpayer_id'])\n",
        "    )\n",
        "\n",
        "power_law_df = pd.DataFrame(power_law_transactions)\n",
        "power_law_df.head()\n",
        "\n",
        "\n",
        "# Create undeclared transactions\n",
        "n_undeclared = int(n_transactions * undeclared_ratio)\n",
        "declared_df = power_law_df[power_law_df['declared'] == 1]\n",
        "\n",
        "undeclared_power_law_transactions = []\n",
        "\n",
        "for _ in trange(n_undeclared):\n",
        "    # Choose a random declared transaction with a large buyer\n",
        "    ref_tx = declared_df.sample(1).iloc[0]\n",
        "    buyer_id = ref_tx['buyer_id']\n",
        "    buyer = all_taxpayers_df[all_taxpayers_df['taxpayer_id'] == buyer_id].iloc[0]\n",
        "\n",
        "    # Find small sellers (e.g., in bottom 30% size)\n",
        "    small_sellers = all_taxpayers_df[\n",
        "            (all_taxpayers_df['size'] < all_taxpayers_df['size'].quantile(0.3)) &\n",
        "            (all_taxpayers_df['location'] == ref_tx['location']) &\n",
        "            (all_taxpayers_df['economic_sector'] == ref_tx['economic_sector']) &\n",
        "            (all_taxpayers_df['taxpayer_id'] != buyer_id)\n",
        "        ]\n",
        "\n",
        "    if small_sellers.empty:\n",
        "        continue\n",
        "\n",
        "    seller = small_sellers.sample(1).iloc[0]\n",
        "\n",
        "    undeclared_power_law_transactions.append(\n",
        "        generate_transaction(seller['taxpayer_id'], buyer['taxpayer_id'], 0)\n",
        "    )\n",
        "\n",
        "undeclared_power_law_df = pd.DataFrame(undeclared_power_law_transactions)\n",
        "\n",
        "power_law_df = pd.concat([power_law_df, undeclared_power_law_df], ignore_index=True)\n",
        "\n",
        "power_law_df.to_csv(csv_file_path+'/power_law_transactions'+ver+'.csv')\n",
        "\n",
        "print(len(power_law_df))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 190000/190000 [03:55<00:00, 805.26it/s]\n100%|██████████| 10000/10000 [00:39<00:00, 252.23it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "33056\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1748536098817
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Location and sector trade flow mapping (example)\n",
        "\n",
        "\n",
        "location_sector_flows = {\n",
        "    ('Thika', 'Nairobi'): [ 'Manufacturing', 'Agriculture', 'Retail', 'Wholesale', 'Construction'],\n",
        "    ('Nakuru', 'Nairobi'): ['Agriculture', 'Retail', 'Construction'],\n",
        "    ('Kisumu', 'Nairobi'): ['Retail', 'ICT', 'Wholesale'],\n",
        "    ('Nyeri', 'Kericho'): ['Manufacturing', 'Agriculture', 'Energy'],\n",
        "    ('Eldoret', 'Thika'): ['Agriculture', 'Manufacturing', 'Transport'],\n",
        "    ('Machakos', 'Nairobi'): ['Construction', 'Logistics'],\n",
        "    ('Nairobi', 'Mombasa'): ['ICT', 'Finance', 'Trade'],\n",
        "    ('Mombasa', 'Nairobi'): ['Logistics', 'Wholesale', 'Hospitality', 'Manufacturing', 'Construction', 'Energy', 'Transport', 'Trade']\n",
        "}\n",
        "\n",
        "\n",
        "location_sector_transactions = []\n",
        "# Declared transactions\n",
        "for _ in trange(n_declared):\n",
        "    seller = sellers.sample(weights=sellers['norm_size']).iloc[0]\n",
        "    origin = seller['location']\n",
        "\n",
        "    # Check if origin has a structured flow\n",
        "    matches = [k for k in location_sector_flows if k[0] == origin]\n",
        "    if matches:\n",
        "        # Pick a destination and sector this origin sells to\n",
        "        dest_pair = random.choice(matches)\n",
        "        dest_location = dest_pair[1]\n",
        "        expected_sector = location_sector_flows[dest_pair]\n",
        "\n",
        "        # Seller must be from the expected sector\n",
        "        if seller['economic_sector'] != expected_sector:\n",
        "            continue\n",
        "\n",
        "        buyers = all_taxpayers_df[\n",
        "            (all_taxpayers_df['location'] == dest_location) &\n",
        "            (all_taxpayers_df['taxpayer_id'] != seller['taxpayer_id'])\n",
        "        ]\n",
        "    else:\n",
        "        # Random fallback\n",
        "        buyers = all_taxpayers_df[\n",
        "            (all_taxpayers_df['location'] != origin) &\n",
        "            (all_taxpayers_df['taxpayer_id'] != seller['taxpayer_id'])\n",
        "        ]\n",
        "\n",
        "    if buyers.empty:\n",
        "        continue\n",
        "\n",
        "    buyer = buyers.sample(weights=buyers['norm_size']).iloc[0]\n",
        "\n",
        "    location_sector_transactions.append(\n",
        "        generate_transaction(seller['taxpayer_id'], buyer['taxpayer_id'], 1)\n",
        "    )\n",
        "\n",
        "\n",
        "# Undeclared transactions: sellers from correct sector & location don't declare\n",
        "for _ in trange(n_undeclared):\n",
        "    dest_pair = random.choice(list(location_sector_flows.keys()))\n",
        "    origin, dest = dest_pair\n",
        "    sector = location_sector_flows[dest_pair]\n",
        "\n",
        "    small_sellers = all_taxpayers_df[\n",
        "        (all_taxpayers_df['location'] == origin) &\n",
        "        (all_taxpayers_df['economic_sector'] == sector) &\n",
        "        (all_taxpayers_df['size'] < all_taxpayers_df['size'].quantile(0.3))\n",
        "    ]\n",
        "    buyers = all_taxpayers_df[all_taxpayers_df['location'] == dest]\n",
        "\n",
        "    if small_sellers.empty or buyers.empty:\n",
        "        continue\n",
        "\n",
        "    seller = small_sellers.sample(1).iloc[0]\n",
        "    buyer = buyers.sample(1).iloc[0]\n",
        "\n",
        "    location_sector_transactions.append(\n",
        "        generate_transaction(seller['taxpayer_id'], buyer['taxpayer_id'], 0)\n",
        "    )\n",
        "\n",
        "location_sector_transactions_df = pd.DataFrame(location_sector_transactions)\n",
        "\n",
        "location_sector_transactions_df.to_csv(csv_file_path+'/location_sector_transactions'+ver+'.csv')\n",
        "\n",
        "print(len(location_sector_transactions_df))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 190000/190000 [05:24<00:00, 585.59it/s]\n100%|██████████| 10000/10000 [00:30<00:00, 326.89it/s]"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "108960\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1748536454779
        },
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sector burst sales\n",
        "\n",
        "sector_burst_transactions = []\n",
        "\n",
        "# def normalize(w): return [x / sum(w) for x in w]\n",
        "\n",
        "for sector, weights in sector_burst_weights.items():\n",
        "    sector_taxpayers = all_taxpayers_df[all_taxpayers_df['economic_sector'] == sector]\n",
        "    if sector_taxpayers.empty:\n",
        "        continue\n",
        "\n",
        "    small_taxpayers = sector_taxpayers[sector_taxpayers['size'] < sector_taxpayers['size'].quantile(0.5)]\n",
        "    if len(small_taxpayers) < 2:\n",
        "        continue\n",
        "\n",
        "    n_sector_txns = int(n_transactions * (len(sector_taxpayers) / len(all_taxpayers_df)))\n",
        "    n_declared = int(n_sector_txns * (1 - undeclared_ratio))\n",
        "    n_undeclared = n_sector_txns - n_declared\n",
        "\n",
        "    # --- Valid pairs for declared txns ---\n",
        "    valid_pairs = [\n",
        "        (s['taxpayer_id'], b['taxpayer_id'])\n",
        "        for i, s in small_taxpayers.iterrows()\n",
        "        for j, b in small_taxpayers.iterrows()\n",
        "        if s['taxpayer_id'] != b['taxpayer_id']\n",
        "        and (s['taxpayer_id'], b['taxpayer_id']) not in invalid_transactions\n",
        "        and is_valid_transaction(s['economic_sector'], b['economic_sector'])\n",
        "    ]\n",
        "\n",
        "    if not valid_pairs:\n",
        "        continue\n",
        "\n",
        "    sampled_declared = random.choices(valid_pairs, k=n_declared)\n",
        "\n",
        "    for seller_id, buyer_id in tqdm(sampled_declared, desc=\"Generating declared transactions\"):\n",
        "        sector_burst_transactions.append(generate_transaction(seller_id, buyer_id, 1))\n",
        "\n",
        "    # --- Undeclared transactions ---\n",
        "    sampled_undeclared = random.choices(valid_pairs, k=n_undeclared)\n",
        "\n",
        "    for seller_id, buyer_id in tqdm(sampled_undeclared, desc=\"Generating undeclared transactions\"):\n",
        "        sector_burst_transactions.append(generate_transaction(seller_id, buyer_id, 0))\n",
        "\n",
        "# Convert to DataFrame\n",
        "sector_burst_transactions_df = pd.DataFrame(sector_burst_transactions)\n",
        "\n",
        "sector_burst_transactions_df.to_csv(csv_file_path+'/sector_burst_transactions'+ver+'.csv')\n",
        "\n",
        "print(len(sector_burst_transactions_df))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Generating declared transactions: 100%|██████████| 8107/8107 [00:00<00:00, 46467.92it/s]\nGenerating undeclared transactions: 100%|██████████| 427/427 [00:00<00:00, 44566.96it/s]\nGenerating declared transactions: 100%|██████████| 7976/7976 [00:00<00:00, 45739.92it/s]\nGenerating undeclared transactions: 100%|██████████| 420/420 [00:00<00:00, 44241.49it/s]\nGenerating declared transactions: 100%|██████████| 8088/8088 [00:00<00:00, 45713.99it/s]\nGenerating undeclared transactions: 100%|██████████| 426/426 [00:00<00:00, 43155.65it/s]\nGenerating declared transactions:   0%|          | 0/8295 [00:00<?, ?it/s]"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "34176\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1748536462451
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_transactions_df = pd.concat([power_law_df,location_sector_transactions_df, sector_burst_transactions_df], axis = 0) \n",
        "print(len(all_transactions_df))\n",
        "all_transactions_df.to_csv(csv_file_path+'/all_transactions'+ver+'.csv')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "176192\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1748536463256
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml.entities import Data\n",
        "from pathlib import Path\n",
        "\n",
        "# Initialize ML client\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(),\n",
        "    subscription_id=\"2550d0cd-923a-4266-9fd3-c574cbc5929e\",\n",
        "    resource_group_name=\"brianombega-rg\",\n",
        "    workspace_name=\"Masters_Ombega\"\n",
        ")\n",
        "\n",
        "# Define the data asset\n",
        "data_asset = Data(\n",
        "    path=Path(csv_file_path+'/all_transactions'+ver+'.csv'),  # local path to your CSV file\n",
        "    type=\"uri_file\",           # or \"uri_folder\" if uploading a folder\n",
        "    name=\"my-generated-vat-data\",        # unique name for the asset\n",
        "    description=\"My dataset as a CSV\",\n",
        "    version=\"22\"\n",
        "    )\n",
        "# Register (upload) the data asset\n",
        "ml_client.data.create_or_update(data_asset)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Overriding of current TracerProvider is not allowed\nOverriding of current LoggerProvider is not allowed\nOverriding of current MeterProvider is not allowed\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "Data({'path': 'azureml://subscriptions/2550d0cd-923a-4266-9fd3-c574cbc5929e/resourcegroups/brianombega-rg/workspaces/Masters_Ombega/datastores/workspaceblobstore/paths/LocalUpload/b05954d04e3c4a1d12c53febae32faee/all_transactions_337_.csv', 'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'my-generated-vat-data', 'description': 'My dataset as a CSV', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/2550d0cd-923a-4266-9fd3-c574cbc5929e/resourceGroups/brianombega-rg/providers/Microsoft.MachineLearningServices/workspaces/Masters_Ombega/data/my-generated-vat-data/versions/22', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/brianombega3/code/Users/brianombega', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7978cc16bd90>, 'serialize': <msrest.serialization.Serializer object at 0x7978875a0a60>, 'version': '22', 'latest_version': None, 'datastore': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1748537448590
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}