{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "import pickle\n",
        "random.seed(42)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1748446568084
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ver = str(random.randint(100, 7000))\n",
        "ver"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "'5338'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1748446570412
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sector_details = {\n",
        "    'Retail': {\n",
        "        'outputs': [\n",
        "            'Clothing', 'Electronics', 'Groceries', 'Furniture',\n",
        "            'Footwear', 'Kitchenware', 'Curtains', 'Carpets',\n",
        "            'Cleaning supplies', 'Detergents'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Packaging materials', 'Processed goods', 'Wholesale products'\n",
        "        ]\n",
        "    },\n",
        "    'Manufacturing': {\n",
        "        'outputs': [\n",
        "            'Plastic containers', 'Steel rods', 'Machinery parts',\n",
        "            'Industrial chemicals', 'Packaging materials', 'Bottling equipment'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Raw materials', 'Steel', 'Plastic pellets', 'Machinery', 'Fertilizer'\n",
        "        ]\n",
        "    },\n",
        "    'Agriculture': {\n",
        "        'outputs': [\n",
        "            'Maize', 'Animal feed'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Fertilizer', 'Pesticides', 'Irrigation equipment', 'Greenhouse materials'\n",
        "        ]\n",
        "    },\n",
        "    'Construction': {\n",
        "        'outputs': [\n",
        "            'Cement', 'Bricks', 'Timber',\n",
        "            'Paints', 'Tiles', 'Electrical fittings', 'Sanitary ware'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Machinery parts', 'Steel rods', 'Consulting service'\n",
        "        ]\n",
        "    },\n",
        "    'ICT': {\n",
        "        'outputs': [\n",
        "            'Software license', 'Network hardware', 'Cloud services',\n",
        "            'Web hosting', 'Domain registration', 'Streaming software'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Consulting service', 'Servers', 'Electricity token'\n",
        "        ]\n",
        "    },\n",
        "    'Finance': {\n",
        "        'outputs': [\n",
        "            'Consulting service', 'Insurance package', 'Audit report',\n",
        "            'Tax return preparation', 'Valuation service', 'Banking software'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'ICT services', 'Legal advice'\n",
        "        ]\n",
        "    },\n",
        "    'Hospitality': {\n",
        "        'outputs': [\n",
        "            'Room booking', 'Conference catering', 'Event services',\n",
        "            'Restaurant meals', 'Spa treatment', 'Tour packages'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Food supplies', 'Laundry services', 'Maintenance services'\n",
        "        ]\n",
        "    },\n",
        "    'Healthcare': {\n",
        "        'outputs': [\n",
        "            'Medicine', 'Medical checkup', 'Diagnostic equipment',\n",
        "            'Surgical tools', 'Lab reagents', 'Dental services'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Pharmaceutical supplies', 'ICT systems', 'Cleaning supplies'\n",
        "        ]\n",
        "    },\n",
        "    'Education': {\n",
        "        'outputs': [\n",
        "            'Tuition fee', 'Training course', 'Learning materials',\n",
        "            'e-Learning platforms', 'Workshop kits', 'Library subscriptions'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Stationery', 'Consulting service', 'Furniture'\n",
        "        ]\n",
        "    },\n",
        "    'Real Estate': {\n",
        "        'outputs': [\n",
        "            'Rent', 'Property sale', 'Land lease',\n",
        "            'Property management fee', 'Valuation report', 'Office space letting'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Construction materials', 'Legal services', 'Cleaning supplies'\n",
        "        ]\n",
        "    },\n",
        "    'Transportation & Logistics': {\n",
        "        'outputs': [\n",
        "            'Cargo delivery', 'Taxi ride', 'Freight service',\n",
        "            'Vehicle leasing', 'Warehousing', 'Courier service'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Fuel supply', 'Vehicle maintenance services', 'Spare parts'\n",
        "        ]\n",
        "    },\n",
        "    'Telecommunications': {\n",
        "        'outputs': [\n",
        "            'Internet bundle', 'Phone service', 'Hosting package',\n",
        "            'Data services', 'Mobile money API', 'SMS bulk services'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Network hardware', 'Electricity', 'Maintenance services'\n",
        "        ]\n",
        "    },\n",
        "    'Energy': {\n",
        "        'outputs': [\n",
        "            'Diesel', 'Electricity token', 'Solar panel',\n",
        "            'Generators', 'Gas cylinders', 'Inverters'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Fuel', 'Regulatory licenses', 'Transport services'\n",
        "        ]\n",
        "    },\n",
        "    'Legal & Professional Services': {\n",
        "        'outputs': [\n",
        "            'Legal advice', 'Contract drafting', 'Tax consulting',\n",
        "            'Company registration', 'Notarization', 'Intellectual property filing'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'ICT systems', 'Office rent'\n",
        "        ]\n",
        "    },\n",
        "    'Mining & Quarrying': {\n",
        "        'outputs': [\n",
        "            'Building stones', 'Limestone', 'Industrial minerals',\n",
        "            'Drilling services', 'Explosives', 'Ore concentrates'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Machinery parts', 'Fuel supply', 'Protective gear'\n",
        "        ]\n",
        "    },\n",
        "    'Entertainment & Media': {\n",
        "        'outputs': [\n",
        "            'Event ticket', 'TV advert', 'Media rights',\n",
        "            'Streaming subscription', 'Film licensing', 'Advertising space'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Production equipment', 'Legal advice', 'IT support'\n",
        "        ]\n",
        "    },\n",
        "    'Public Administration': {\n",
        "        'outputs': [\n",
        "            'Government publications', 'Passport fees', 'Regulatory licenses'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Printing services', 'ICT systems'\n",
        "        ]\n",
        "    },\n",
        "    'Water & Sanitation': {\n",
        "        'outputs': [\n",
        "            'Bottled water', 'Water purification units', 'Sewerage services'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Water treatment chemicals', 'Energy', 'Engineering services'\n",
        "        ]\n",
        "    },\n",
        "    'Waste Management': {\n",
        "        'outputs': [\n",
        "            'Garbage collection', 'Recycling bins', 'Hazardous waste disposal'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Protective gear', 'Vehicles', 'Fuel'\n",
        "        ]\n",
        "    },\n",
        "    'Security Services': {\n",
        "        'outputs': [\n",
        "            'Alarm installation', 'Private guard services', 'Surveillance systems'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Security hardware', 'Training services'\n",
        "        ]\n",
        "    },\n",
        "    'Wholesale Trade': {\n",
        "        'outputs': [\n",
        "            'Bulk groceries', 'Bulk electronics', 'Distribution services'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Manufactured goods', 'Packaging materials'\n",
        "        ]\n",
        "    },\n",
        "    'Arts & Culture': {\n",
        "        'outputs': [\n",
        "            'Art exhibition tickets', 'Craft supplies', 'Museum entrance fees'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Venue rental', 'Marketing services'\n",
        "        ]\n",
        "    },\n",
        "    'Transportation': {\n",
        "        'outputs': [\n",
        "            'Vehicle hire', 'Freight services', 'Passenger transport',\n",
        "            'Logistics consulting', 'Spare parts', 'Fuel supply',\n",
        "            'Vehicle maintenance services', 'Courier services'\n",
        "        ],\n",
        "        'inputs': [\n",
        "            'Fuel', 'Vehicles', 'Logistics software', 'Tyres'\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "sectors = list(sector_details.keys())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Save to pickle file\n",
        "with open('sector_details.pkl', 'wb') as f:\n",
        "    pickle.dump(sector_details, f)\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1748446573415
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "allowed_sector_transactions = allowed_links = {\n",
        "    'Retail': ['Wholesale Trade', 'Manufacturing', 'Agriculture', 'Transportation & Logistics', 'ICT', 'Finance'],\n",
        "    'Manufacturing': ['Agriculture', 'Mining & Quarrying', 'Energy', 'Transportation & Logistics', 'Wholesale Trade', 'Construction'],\n",
        "    'Agriculture': ['Manufacturing', 'Wholesale Trade', 'Retail', 'Water & Sanitation', 'Finance'],\n",
        "    'Construction': ['Manufacturing', 'Wholesale Trade', 'Energy', 'Transportation & Logistics', 'Finance', 'Legal & Professional Services'],\n",
        "    'ICT': ['Finance', 'Telecommunications', 'Education', 'Healthcare', 'Legal & Professional Services', 'Retail', 'Entertainment & Media'],\n",
        "    'Finance': ['All'],  # Often connects to all sectors\n",
        "    'Hospitality': ['Agriculture', 'Wholesale Trade', 'Retail', 'Transportation & Logistics', 'Entertainment & Media'],\n",
        "    'Healthcare': ['Pharmaceuticals', 'Manufacturing', 'ICT', 'Education', 'Energy', 'Waste Management'],\n",
        "    'Education': ['ICT', 'Finance', 'Publishing', 'Retail', 'Public Administration'],\n",
        "    'Real Estate': ['Construction', 'Finance', 'Legal & Professional Services', 'Public Administration'],\n",
        "    'Transportation & Logistics': ['Wholesale Trade', 'Retail', 'Manufacturing', 'Energy', 'Agriculture', 'Mining & Quarrying'],\n",
        "    'Telecommunications': ['ICT', 'Finance', 'Education', 'Entertainment & Media'],\n",
        "    'Energy': ['Manufacturing', 'Mining & Quarrying', 'Construction', 'Transportation & Logistics', 'Water & Sanitation'],\n",
        "    'Legal & Professional Services': ['Finance', 'Real Estate', 'Construction', 'Public Administration', 'Healthcare'],\n",
        "    'Mining & Quarrying': ['Manufacturing', 'Construction', 'Energy', 'Transportation & Logistics'],\n",
        "    'Entertainment & Media': ['Retail', 'ICT', 'Arts & Culture', 'Telecommunications', 'Public Administration'],\n",
        "    'Public Administration': ['All'],  # Purchases from many sectors\n",
        "    'Water & Sanitation': ['Construction', 'Agriculture', 'Public Administration', 'Healthcare'],\n",
        "    'Waste Management': ['Healthcare', 'Construction', 'Public Administration', 'Water & Sanitation'],\n",
        "    'Security Services': ['Retail', 'Finance', 'Public Administration', 'Real Estate', 'Healthcare'],\n",
        "    'Wholesale Trade': ['Manufacturing', 'Agriculture', 'Retail', 'Transportation & Logistics'],\n",
        "    'Arts & Culture': ['Education', 'Entertainment & Media', 'Retail', 'Public Administration'],\n",
        "    'Transportation': ['Retail', 'Wholesale Trade', 'Agriculture', 'Construction', 'Healthcare']\n",
        "}\n",
        "\n",
        "locations = [\n",
        "    'Nairobi', 'Mombasa', 'Kisumu', 'Eldoret', 'Nakuru', 'Thika', 'Machakos',\n",
        "    'Kericho', 'Nyeri', 'Garissa', 'Meru', 'Kitale'\n",
        "]\n",
        "\n",
        "def is_valid_transaction(seller_sector, buyer_sector):\n",
        "    allowed = allowed_links.get(seller_sector, [])\n",
        "    return buyer_sector in allowed or 'All' in allowed or random.random() < 0.05  # 5% noise\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1748446580792
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Settings ===\n",
        "n_individuals = 1000\n",
        "n_non_individuals = 50000\n",
        "n_transactions = 5000 * 12\n",
        "valid_transactions = 0\n",
        "max_attempts = n_transactions * 2\n",
        "vat_rates = [0.16, 0.00]"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1748241868895
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Generate Individuals ===\n",
        "individuals = []\n",
        "\n",
        "def random_registration_date(start_year=2005, end_year=2024):\n",
        "    start_date = datetime(start_year, 1, 1)\n",
        "    end_date = datetime(end_year, 12, 31)\n",
        "    delta = end_date - start_date\n",
        "    return start_date + timedelta(days=random.randint(0, delta.days))\n",
        "\n",
        "individuals = []\n",
        "for i in range(1, n_individuals + 1):\n",
        "    taxpayer_id = f\"A{str(i).zfill(4)}\"\n",
        "    individuals.append({\n",
        "        'taxpayer_id': taxpayer_id,\n",
        "        'location': random.choice(locations),\n",
        "        'economic_sector': random.choice(sectors),\n",
        "        'entity_type': 'Individual',\n",
        "        'beneficial_owners': [taxpayer_id],  # self-owned\n",
        "        'registration_date': random_registration_date().date()  # Add as ISO date\n",
        "    })\n",
        "\n",
        "individuals_df = pd.DataFrame(individuals)\n",
        "\n",
        "individuals_df.head()\n",
        "\n",
        "\n",
        "#get a sampele of individuals to act as directors\n",
        "\n",
        "\n",
        "directors_df = individuals_df.sample(n=100, random_state=42)\n",
        "directors_df.head() \n",
        "\n",
        "directors_df.to_csv('csv_files/director_df_'+ver+'.csv')\n",
        "\n",
        "# === Generate Non-Individuals (Companies, etc.) ===\n",
        "list_of_directors = directors_df['taxpayer_id'].to_list()\n",
        "\n",
        "non_individuals = []\n",
        "for i in range(1, n_non_individuals + 1):\n",
        "    taxpayer_id = f\"P{str(i).zfill(4)}\"\n",
        "    owners = random.sample(list_of_directors, k=random.randint(1, 3))\n",
        "    non_individuals.append({\n",
        "        'taxpayer_id': taxpayer_id,\n",
        "        'location': random.choice(locations),\n",
        "        'economic_sector': random.choice(sectors),\n",
        "        'entity_type': 'Non-Individual',\n",
        "        'beneficial_owners': owners,\n",
        "        'registration_date': random_registration_date().date()  # Add as ISO date\n",
        "    })\n",
        "\n",
        "non_individuals_df = pd.DataFrame(non_individuals)\n",
        "\n",
        "\n",
        "\n",
        "beneficial_owners_df = non_individuals_df[['taxpayer_id', 'beneficial_owners']]\n",
        "\n",
        "beneficial_owners_df.to_csv('csv_files/beneficial_owners_df_'+ver+'.csv')\n",
        "\n",
        "# === Combine for Transaction Pool ===\n",
        "all_taxpayers_df = pd.concat([individuals_df, non_individuals_df], ignore_index=True)\n",
        "\n",
        "all_taxpayers_df.to_csv('csv_files/all_taxpayers_df_'+ver+'.csv')"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1748241875164
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate a set of non-individuals that share at least 1 directors\n",
        "from collections import defaultdict\n",
        "\n",
        "# Step 1: Build a mapping from each director to the non-individuals they are associated with\n",
        "director_to_taxpayers = defaultdict(set)\n",
        "\n",
        "for _, row in non_individuals_df.iterrows():\n",
        "    for owner in row['beneficial_owners']:\n",
        "        director_to_taxpayers[owner].add(row['taxpayer_id'])\n",
        "\n",
        "# Step 2: For each non-individual, find others with whom it shares at least one director\n",
        "shared_director_map = defaultdict(set)\n",
        "\n",
        "for owner, taxpayers in director_to_taxpayers.items():\n",
        "    for taxpayer in taxpayers:\n",
        "        shared_director_map[taxpayer].update(taxpayers - {taxpayer})  # exclude self\n",
        "\n",
        "# Step 3 (Optional): Convert to DataFrame for inspection\n",
        "shared_directors_df = pd.DataFrame([\n",
        "    {'taxpayer_id': taxpayer, 'shared_with': list(others)}\n",
        "    for taxpayer, others in shared_director_map.items() if others\n",
        "])\n",
        "\n",
        "\n",
        "shared_directors_df.to_csv('csv_files/shared_directors'+ver+'.csv')"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1748241881525
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_taxpayers_df.head()\n",
        "all_taxpayers_df['size'] = np.random.pareto(a=2, size=len(all_taxpayers_df)) + 1\n",
        "# Normalize sizes for probability distribution\n",
        "all_taxpayers_df['norm_size'] = all_taxpayers_df['size'] / all_taxpayers_df['size'].sum()\n",
        "\n",
        "\n",
        "# Add size category to taxpayers\n",
        "quantiles = all_taxpayers_df['size'].quantile([0.25, 0.5, 0.75])\n",
        "\n",
        "def categorize_size(size):\n",
        "    if size <= quantiles[0.25]:\n",
        "        return 'micro'\n",
        "    elif size <= quantiles[0.5]:\n",
        "        return 'small'\n",
        "    elif size <= quantiles[0.75]:\n",
        "        return 'medium'\n",
        "    else:\n",
        "        return 'large'\n",
        "\n",
        "all_taxpayers_df['size_category'] = all_taxpayers_df['size'].apply(categorize_size)\n",
        "all_taxpayers_df.head()\n",
        "all_taxpayers_df.to_csv('all_taxpayers.csv')\n"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1748242459871
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# === Generate VAT Transactions ===\n",
        "\n",
        "invoice_statuses = ['Paid', 'Pending', 'Cancelled', 'Disputed']\n",
        "payment_methods = ['Bank Transfer', 'Mobile Money', 'Cash', 'Cheque', 'Credit']\n",
        "\n",
        "existing_pairs = []\n",
        "pair_reuse_probability = 0.3  # 30% of transactions will reuse a pair\n",
        "\n",
        "transactions = []"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1748241885729
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sector_burst_weights = {\n",
        "    'Retail': [0.05, 0.05, 0.1, 0.15, 0.1, 0.15, 0.05, 0.05, 0.1, 0.1, 0.2, 0.3],  # Higher burst during Nov-Dec\n",
        "    'Agriculture': [0.05, 0.05, 0.1, 0.1, 0.1, 0.05, 0.05, 0.05, 0.1, 0.2, 0.15, 0.2],  # Peak in October\n",
        "    'Hospitality': [0.1, 0.05, 0.05, 0.1, 0.15, 0.1, 0.1, 0.15, 0.05, 0.05, 0.15, 0.2],  # Summer & December peaks\n",
        "    'Transportation & Logistics': [0.05, 0.05, 0.1, 0.1, 0.1, 0.1, 0.15, 0.1, 0.05, 0.1, 0.2, 0.25],  # High at holidays, peak season\n",
        "    'Other': [0.05] * 12  # Default: uniform, no specific seasonal peaks\n",
        "}\n",
        "\n",
        "\n",
        "# Function to sample date with seasonality and burst variations\n",
        "def sample_seasonal_date(sector):\n",
        "    # Get the sector's seasonal burst weights\n",
        "    monthly_weights = sector_burst_weights.get(sector, sector_burst_weights['Other'])\n",
        "\n",
        "    # Choose month with seasonal probability\n",
        "    month = random.choices(range(12), weights=monthly_weights)[0]\n",
        "\n",
        "    # Optionally introduce bursts during specific weeks for certain sectors\n",
        "    burst_weeks = [10, 25, 27, 33, 48, 50]  # Defined burst weeks\n",
        "    burst_probability = 0.1  # 10% chance for a burst event\n",
        "\n",
        "    if random.random() < burst_probability:\n",
        "        week = random.choice(burst_weeks)\n",
        "        weekday = random.randint(0, 6)  # Random day in the week\n",
        "        date = datetime.strptime(f'2022-W{week:02d}-{weekday}', \"%Y-W%W-%w\")\n",
        "    else:\n",
        "        # Sample a date based on monthly weights\n",
        "        day = random.randint(1, 28)  # Safe for all months\n",
        "        date = datetime(2022, month + 1, day)\n",
        "    \n",
        "    return date\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1748241888518
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#generate \n",
        "\n",
        "\n",
        "\n",
        "# # Function to simulate declared transactions\n",
        "# def simulate_transactions(taxpayers, n_transactions=10000, undeclared_ratio=0.05):\n",
        "buyers = all_taxpayers_df.copy()\n",
        "sellers = all_taxpayers_df.copy()\n",
        "\n",
        "power_law_transactions = []\n",
        "high_degree_buyers = buyers.nlargest(10, 'size')['taxpayer_id'].tolist()\n",
        "\n",
        "for _ in range(n_transactions):\n",
        "    # Power-law selection: buyers are skewed toward large firms\n",
        "    # Preselect a small number of dominant buyers\n",
        "    \n",
        "    buyer_id = random.choice(high_degree_buyers)\n",
        "    buyer = buyers[buyers['taxpayer_id'] == buyer_id].iloc[0]\n",
        "    seller = sellers.sample(weights=sellers['norm_size']).iloc[0]\n",
        "\n",
        "    # Prevent self-transactions\n",
        "    if seller['taxpayer_id'] == buyer['taxpayer_id']:\n",
        "        continue\n",
        "    if not is_valid_transaction(seller['economic_sector'], buyer['economic_sector']):\n",
        "        continue\n",
        "    \n",
        "\n",
        "    power_law_transactions.append(\n",
        "        generate_transaction(seller['taxpayer_id'], buyer['taxpayer_id'])\n",
        "    )\n",
        "\n",
        "power_law_df = pd.DataFrame(power_law_transactions)\n",
        "power_law_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "  seller_id buyer_id invoice_number  description_of_goods  sales_amount  \\\n0     A0999    A0158      INV387230           Animal feed      21027.60   \n1     P1426    A0457      INV108739  Company registration      79635.62   \n2     P1340    P0070      INV610472      Ore concentrates      15447.66   \n3     P0112    P0582      INV974627        Cloud services      82634.32   \n4     A0974    P1353      INV262568           Solar panel      87932.85   \n\n   vat_amount  total_amount invoice_date invoice_status payment_method  \\\n0     3364.42      24392.02   2022-12-04        Pending         Credit   \n1    12741.70      92377.32   2022-10-04           Paid   Mobile Money   \n2        0.00      15447.66   2022-08-10           Paid           Cash   \n3    13221.49      95855.81   2022-07-08           Paid           Cash   \n4    14069.26     102002.11   2022-07-18       Disputed           Cash   \n\n   declared  \n0         1  \n1         1  \n2         1  \n3         1  \n4         1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seller_id</th>\n      <th>buyer_id</th>\n      <th>invoice_number</th>\n      <th>description_of_goods</th>\n      <th>sales_amount</th>\n      <th>vat_amount</th>\n      <th>total_amount</th>\n      <th>invoice_date</th>\n      <th>invoice_status</th>\n      <th>payment_method</th>\n      <th>declared</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A0999</td>\n      <td>A0158</td>\n      <td>INV387230</td>\n      <td>Animal feed</td>\n      <td>21027.60</td>\n      <td>3364.42</td>\n      <td>24392.02</td>\n      <td>2022-12-04</td>\n      <td>Pending</td>\n      <td>Credit</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>P1426</td>\n      <td>A0457</td>\n      <td>INV108739</td>\n      <td>Company registration</td>\n      <td>79635.62</td>\n      <td>12741.70</td>\n      <td>92377.32</td>\n      <td>2022-10-04</td>\n      <td>Paid</td>\n      <td>Mobile Money</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>P1340</td>\n      <td>P0070</td>\n      <td>INV610472</td>\n      <td>Ore concentrates</td>\n      <td>15447.66</td>\n      <td>0.00</td>\n      <td>15447.66</td>\n      <td>2022-08-10</td>\n      <td>Paid</td>\n      <td>Cash</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>P0112</td>\n      <td>P0582</td>\n      <td>INV974627</td>\n      <td>Cloud services</td>\n      <td>82634.32</td>\n      <td>13221.49</td>\n      <td>95855.81</td>\n      <td>2022-07-08</td>\n      <td>Paid</td>\n      <td>Cash</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A0974</td>\n      <td>P1353</td>\n      <td>INV262568</td>\n      <td>Solar panel</td>\n      <td>87932.85</td>\n      <td>14069.26</td>\n      <td>102002.11</td>\n      <td>2022-07-18</td>\n      <td>Disputed</td>\n      <td>Cash</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1748243680604
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create undeclared transactions\n",
        "n_undeclared = int(n_transactions * undeclared_ratio)\n",
        "declared_df = df[df['declared'] == 1]\n",
        "\n",
        "undeclared_transactions = []\n",
        "\n",
        "for _ in range(n_undeclared):\n",
        "    # Choose a random declared transaction with a large buyer\n",
        "    ref_tx = declared_df.sample(1).iloc[0]\n",
        "    buyer_id = ref_tx['buyer_id']\n",
        "    buyer = taxpayers[taxpayers['taxpayer_id'] == buyer_id].iloc[0]\n",
        "\n",
        "    # Find small sellers (e.g., in bottom 30% size)\n",
        "        small_sellers = taxpayers[\n",
        "            (taxpayers['size'] < taxpayers['size'].quantile(0.3)) &\n",
        "            (taxpayers['region'] == ref_tx['region']) &\n",
        "            (taxpayers['economic_activity'] == ref_tx['economic_activity']) &\n",
        "            (taxpayers['taxpayer_id'] != buyer_id)\n",
        "        ]\n",
        "\n",
        "        if small_sellers.empty:\n",
        "            continue\n",
        "\n",
        "        seller = small_sellers.sample(1).iloc[0]\n",
        "\n",
        "        undeclared_transactions.append({\n",
        "            'buyer_id': buyer_id,\n",
        "            'seller_id': seller['taxpayer_id'],\n",
        "            'amount': np.round(np.random.exponential(scale=10000), 2),\n",
        "            'declared': 0,\n",
        "            'region': seller['region'],\n",
        "            'invoice_date' : sample_seasonal_date(seller['economic_sector']),\n",
        "            'economic_activity': seller['economic_activity']\n",
        "        })\n",
        "\n",
        "    undeclared_df = pd.DataFrame(undeclared_transactions)\n",
        "\n",
        "    return pd.concat([df, undeclared_df], ignore_index=True)\n",
        "\n",
        "# Generate dataset\n",
        "simulated_data = simulate_transactions(taxpayers)\n",
        "\n",
        "# Show a sample\n",
        "print(simulated_data.sample(5))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_transaction(seller_id, buyer_id, declared = 1):\n",
        "    transaction = {}\n",
        "    goods_list = sector_details.get(seller['economic_sector'], {}).get('outputs', ['General Item'])\n",
        "    description = random.choice(goods_list)\n",
        "\n",
        "    sales_amount = round(random.uniform(500, 100000), 2)\n",
        "    vat_rate = random.choices(vat_rates, weights= [0.9, 0.1])[0]\n",
        "    vat_amount = round(sales_amount * vat_rate, 2)\n",
        "    total_amount = round(sales_amount + vat_amount, 2)\n",
        "    invoice_date = sample_seasonal_date(seller['economic_sector'])\n",
        "    invoice_number = f\"INV{random.randint(100000, 999999)}\"\n",
        "    invoice_status = random.choices(invoice_statuses, weights=[0.7, 0.2, 0.05, 0.05])[0]\n",
        "    payment_method = random.choice(payment_methods)\n",
        "\n",
        "    transaction = {\n",
        "    'seller_id': seller['taxpayer_id'],\n",
        "    'buyer_id': buyer['taxpayer_id'],\n",
        "    'invoice_number': invoice_number,\n",
        "    'description_of_goods': description,\n",
        "    'sales_amount': sales_amount,\n",
        "    'vat_amount': vat_amount,\n",
        "    'total_amount': total_amount,\n",
        "    'invoice_date': invoice_date,\n",
        "    'invoice_status': invoice_status,\n",
        "    'payment_method': payment_method,\n",
        "    'declared' : declared\n",
        "}\n",
        "\n",
        "    return transaction"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1748243622140
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#generate first set of transactions without repeat business\n",
        "transactions = []\n",
        "trans = 0\n",
        "\n",
        "while trans < n_transactions:\n",
        "\n",
        "    pair_type = random.choices(['NN', 'IN', 'II', 'NI'], weights=[0.6, 0.25, 0.1, 0.05])[0]\n",
        "\n",
        "    if pair_type == 'NN':\n",
        "        seller_df, purchaser_df = non_individuals_df, non_individuals_df\n",
        "    elif pair_type == 'IN':\n",
        "        seller_df, purchaser_df = individuals_df, non_individuals_df\n",
        "    elif pair_type == 'II':\n",
        "        seller_df, purchaser_df = individuals_df, individuals_df\n",
        "    elif pair_type == 'NI':\n",
        "        seller_df, purchaser_df = non_individuals_df, individuals_df\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected pair_type: {pair_type}\")\n",
        "\n",
        "    # Sample until seller and purchaser are different\n",
        "    while True:\n",
        "        seller = seller_df.sample(1).iloc[0]\n",
        "        purchaser = purchaser_df.sample(1).iloc[0]\n",
        "        if seller['taxpayer_id'] != purchaser['taxpayer_id']:\n",
        "            break\n",
        "\n",
        "\n",
        "    if not is_valid_transaction(seller['economic_sector'], purchaser['economic_sector']):\n",
        "        continue\n",
        "\n",
        "    # Save new pair for possible reuse\n",
        "    existing_pairs.append((seller['taxpayer_id'], purchaser['taxpayer_id']))\n",
        "\n",
        "    transactions.append(\n",
        "        generate_transaction(seller['taxpayer_id'], purchaser['taxpayer_id'])\n",
        "    )\n",
        "    trans += 1\n",
        "\n",
        "transactions_df = pd.DataFrame(transactions)\n",
        "\n",
        "repeat_added = False\n",
        "shared_directors_transactions_added = False"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1747317462928
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#add transactions between existing pairs, this will be about 10% of the total transaction volume\n",
        "repeat_transactions = []\n",
        "if not repeat_added:\n",
        "    n_repeat_transaction = round(len(transactions_df) * 0.1)\n",
        "else:\n",
        "    n_repeat_transaction = 0\n",
        "\n",
        "for _ in range(n_repeat_transaction):\n",
        "    seller_id, purchaser_id = random.choice(existing_pairs)\n",
        "    seller = all_taxpayers_df[all_taxpayers_df['taxpayer_id'] == seller_id].iloc[0]\n",
        "    purchaser = all_taxpayers_df[all_taxpayers_df['taxpayer_id'] == purchaser_id].iloc[0]\n",
        "\n",
        "    repeat_transactions.append(\n",
        "        generate_transaction(seller['taxpayer_id'], purchaser['taxpayer_id'])\n",
        "    )\n",
        "\n",
        "repeat_transactions_df = pd.DataFrame(repeat_transactions)\n",
        "\n",
        "\n",
        "\n",
        "transactions_df = pd.concat([transactions_df, repeat_transactions_df], axis = 0)\n",
        "\n",
        "repeat_added = True\n",
        "\n",
        "\n",
        "\n",
        "transactions_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "  seller_id purchaser_id invoice_number  description_of_goods  sales_amount  \\\n0     P0563        P0596      INV975937         Passport fees      87385.24   \n1     A0948        P1752      INV481985                Paints      49320.85   \n2     P1901        P0070      INV607882  Diagnostic equipment      89191.56   \n3     A0786        P1659      INV705640            Generators      85698.42   \n4     P1399        P0129      INV811774      Freight services      19787.29   \n\n   vat_amount  total_amount invoice_date invoice_status payment_method  \n0    13981.64     101366.88   2022-12-13           Paid         Credit  \n1     7891.34      57212.19   2022-07-09           Paid           Cash  \n2    14270.65     103462.21   2022-11-20           Paid         Credit  \n3    13711.75      99410.17   2022-02-08        Pending         Cheque  \n4        0.00      19787.29   2022-08-21           Paid         Cheque  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seller_id</th>\n      <th>purchaser_id</th>\n      <th>invoice_number</th>\n      <th>description_of_goods</th>\n      <th>sales_amount</th>\n      <th>vat_amount</th>\n      <th>total_amount</th>\n      <th>invoice_date</th>\n      <th>invoice_status</th>\n      <th>payment_method</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P0563</td>\n      <td>P0596</td>\n      <td>INV975937</td>\n      <td>Passport fees</td>\n      <td>87385.24</td>\n      <td>13981.64</td>\n      <td>101366.88</td>\n      <td>2022-12-13</td>\n      <td>Paid</td>\n      <td>Credit</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A0948</td>\n      <td>P1752</td>\n      <td>INV481985</td>\n      <td>Paints</td>\n      <td>49320.85</td>\n      <td>7891.34</td>\n      <td>57212.19</td>\n      <td>2022-07-09</td>\n      <td>Paid</td>\n      <td>Cash</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>P1901</td>\n      <td>P0070</td>\n      <td>INV607882</td>\n      <td>Diagnostic equipment</td>\n      <td>89191.56</td>\n      <td>14270.65</td>\n      <td>103462.21</td>\n      <td>2022-11-20</td>\n      <td>Paid</td>\n      <td>Credit</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0786</td>\n      <td>P1659</td>\n      <td>INV705640</td>\n      <td>Generators</td>\n      <td>85698.42</td>\n      <td>13711.75</td>\n      <td>99410.17</td>\n      <td>2022-02-08</td>\n      <td>Pending</td>\n      <td>Cheque</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P1399</td>\n      <td>P0129</td>\n      <td>INV811774</td>\n      <td>Freight services</td>\n      <td>19787.29</td>\n      <td>0.00</td>\n      <td>19787.29</td>\n      <td>2022-08-21</td>\n      <td>Paid</td>\n      <td>Cheque</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1747317496201
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#generate transactions between entities that share at least 1 director\n",
        "# Flatten shared_director_map into pairs\n",
        "shared_director_pairs = []\n",
        "\n",
        "for seller, purchasers in shared_director_map.items():\n",
        "    for purchaser in purchasers:\n",
        "        shared_director_pairs.append((seller, purchaser))\n",
        "\n",
        "# Deduplicate if needed\n",
        "shared_director_pairs = list(set(shared_director_pairs))\n",
        "\n",
        "\n",
        "n_shared_transactions = int(0.05 * len(transactions_df))\n",
        "sampled_pairs = random.sample(shared_director_pairs, min(n_shared_transactions, len(shared_director_pairs)))"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1747317501382
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shared_directors_transactions = []\n",
        "\n",
        "\n",
        "if not shared_directors_transactions_added:\n",
        "    for seller_id, purchaser_id in sampled_pairs:\n",
        "        seller = non_individuals_df[non_individuals_df['taxpayer_id'] == seller_id].iloc[0]\n",
        "        purchaser = non_individuals_df[non_individuals_df['taxpayer_id'] == purchaser_id].iloc[0]\n",
        "        \n",
        "        # Check economic sector compatibility (optional)\n",
        "        if not is_valid_transaction(seller['economic_sector'], purchaser['economic_sector']):\n",
        "            continue\n",
        "        shared_directors_transactions.append(\n",
        "            generate_transaction(seller['taxpayer_id'], purchaser['taxpayer_id'])\n",
        "\n",
        "        )\n",
        "    shared_directors_transactions_df = pd.DataFrame(shared_directors_transactions)\n",
        "    transactions_df = pd.concat([transactions_df, shared_directors_transactions_df], axis = 0)\n",
        "\n",
        "    shared_directors_transactions_added = True\n",
        "\n",
        "\n",
        "shared_directors_transactions_df.to_csv('csv_files/shared_directors_transactions_'+ver+'.csv')\n"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1747318230974
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_unrelated_goods_dict(sector_details, n_mismatches_per_sector=5):\n",
        "    \"\"\"\n",
        "    Create a dictionary mapping each sector to a list of goods that are unrelated to its usual inputs/outputs.\n",
        "\n",
        "    Parameters:\n",
        "        sector_details (dict): Your sector details dictionary.\n",
        "        n_mismatches_per_sector (int): Number of unrelated goods to sample per sector.\n",
        "\n",
        "    Returns:\n",
        "        dict: Mapping of sector name to a list of unrelated goods.\n",
        "    \"\"\"\n",
        "    # Step 1: Collect all goods from all outputs\n",
        "    all_outputs = []\n",
        "    for sector in sector_details.values():\n",
        "        all_outputs.extend(sector.get('outputs', []))\n",
        "\n",
        "    all_outputs = list(set(all_outputs))  # remove duplicates\n",
        "\n",
        "    # Step 2: Build unrelated goods per sector\n",
        "    unrelated_goods = {}\n",
        "\n",
        "    for sector_name, details in sector_details.items():\n",
        "        sector_goods = set(details.get('outputs', []) + details.get('inputs', []))\n",
        "        unrelated = list(set(all_outputs) - sector_goods)\n",
        "\n",
        "        if unrelated:\n",
        "            sampled = random.sample(unrelated, k=min(n_mismatches_per_sector, len(unrelated)))\n",
        "            unrelated_goods[sector_name] = sampled\n",
        "        else:\n",
        "            unrelated_goods[sector_name] = []\n",
        "\n",
        "    return unrelated_goods\n"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1747317508485
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unrelated_goods_dict = build_unrelated_goods_dict(sector_details)\n",
        "\n",
        "# During simulation\n",
        "sector = seller['economic_sector']\n",
        "mismatch_good = random.choice(unrelated_goods_dict.get(sector, ['Luxury Yacht Service']))\n"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1747317511213
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from datetime import timedelta\n",
        "\n",
        "\n",
        "def generate_fictitious_transactions(transactions_df, n_fictitious=100):\n",
        "    fictitious = []\n",
        "\n",
        "    all_taxpayers = set(transactions_df['seller_id']).union(set(transactions_df['purchaser_id']))\n",
        "    sector_map = dict(zip(transactions_df['seller_id'], transactions_df['description_of_goods']))\n",
        "    \n",
        "    for _ in range(n_fictitious):\n",
        "        heuristic = random.choice(['circular', 'timing', 'mismatch', 'extreme', 'duplicate_invoice'])\n",
        "\n",
        "        if heuristic == 'circular':\n",
        "            parties = random.sample(list(all_taxpayers), 3)\n",
        "            seller, intermediary, purchaser = parties\n",
        "            fictitious.append(generate_transaction(seller, intermediary))\n",
        "            fictitious.append(generate_transaction(intermediary, purchaser))\n",
        "            fictitious.append(generate_transaction(purchaser, seller))\n",
        "\n",
        "        elif heuristic == 'timing':\n",
        "            row = transactions_df.sample(1).iloc[0]\n",
        "            for _ in range(3):\n",
        "                t = row.copy()\n",
        "                t['invoice_date'] = row['invoice_date'] + timedelta(minutes=random.randint(0, 3))\n",
        "                t['invoice_number'] = f\"FTX{random.randint(100000, 999999)}\"\n",
        "                fictitious.append(t.to_dict())\n",
        "\n",
        "        elif heuristic == 'mismatch':\n",
        "            mismatch_good = random.choice(unrelated_goods_dict.get(sector, ['Luxury Yacht Service']))\n",
        "            row = transactions_df.sample(1).iloc[0]\n",
        "            t = row.copy()\n",
        "            t['description_of_goods'] = mismatch_good  # unlikely mismatch\n",
        "            t['invoice_number'] = f\"FTX{random.randint(100000, 999999)}\"\n",
        "            fictitious.append(t.to_dict())\n",
        "\n",
        "        elif heuristic == 'extreme':\n",
        "            row = transactions_df.sample(1).iloc[0]\n",
        "            t = row.copy()\n",
        "            t['sales_amount'] = round(random.uniform(10**6, 10**7), 2)\n",
        "            t['vat_amount'] = round(t['sales_amount'] * 0.16, 2)\n",
        "            t['total_amount'] = t['sales_amount'] + t['vat_amount']\n",
        "            t['invoice_number'] = f\"FTX{random.randint(100000, 999999)}\"\n",
        "            fictitious.append(t.to_dict())\n",
        "\n",
        "        elif heuristic == 'duplicate_invoice':\n",
        "            row = transactions_df.sample(1).iloc[0]\n",
        "            t = row.copy()\n",
        "            t['invoice_number'] = row['invoice_number']  # reusing\n",
        "            fictitious.append(t.to_dict())\n",
        "\n",
        "    return pd.DataFrame(fictitious)\n",
        "\n",
        "def create_transaction(seller_id, purchaser_id, description):\n",
        "    sales_amount = round(random.uniform(1000, 50000), 2)\n",
        "    vat_amount = round(sales_amount * 0.16, 2)\n",
        "    return {\n",
        "        'seller_id': seller_id,\n",
        "        'purchaser_id': purchaser_id,\n",
        "        'invoice_number': f\"FTX{random.randint(100000, 999999)}\",\n",
        "        'description_of_goods': description,\n",
        "        'sales_amount': sales_amount,\n",
        "        'vat_amount': vat_amount,\n",
        "        'total_amount': sales_amount + vat_amount,\n",
        "        'invoice_date': sample_seasonal_date(seller['economic_sector']),\n",
        "        'invoice_status': random.choice(['Valid', 'Cancelled', 'Pending']),\n",
        "        'payment_method': random.choice(['Bank Transfer', 'Cash', 'Mobile Money'])\n",
        "    }\n"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1747317513829
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fictitous_df = generate_fictitious_transactions(transactions_df)\n",
        "\n",
        "transactions_df = pd.concat([transactions_df, fictitous_df], axis = 0)\n",
        "transactions_df.to_csv('csv_files/transactions_'+ver+'.csv')"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1747317517822
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fictitous_df.to_csv('csv_files/fictitous_'+ver+'.csv')"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1747317822400
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml.entities import Data\n",
        "from pathlib import Path\n",
        "\n",
        "# Initialize ML client\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(),\n",
        "    subscription_id=\"2550d0cd-923a-4266-9fd3-c574cbc5929e\",\n",
        "    resource_group_name=\"brianombega-rg\",\n",
        "    workspace_name=\"Masters_Ombega\"\n",
        ")\n",
        "\n",
        "# Define the data asset\n",
        "data_asset = Data(\n",
        "    path=Path(\"vat_transactions.csv\"),  # local path to your CSV file\n",
        "    type=\"uri_file\",           # or \"uri_folder\" if uploading a folder\n",
        "    name=\"my-vat-data\",        # unique name for the asset\n",
        "    description=\"My dataset as a CSV\",\n",
        "    version=\"3\",               # optional: can be auto-versioned\n",
        ")\n",
        "\n",
        "# Register (upload) the data asset\n",
        "ml_client.data.create_or_update(data_asset)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Overriding of current TracerProvider is not allowed\nOverriding of current LoggerProvider is not allowed\nOverriding of current MeterProvider is not allowed\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "Data({'path': 'azureml://subscriptions/2550d0cd-923a-4266-9fd3-c574cbc5929e/resourcegroups/brianombega-rg/workspaces/Masters_Ombega/datastores/workspaceblobstore/paths/LocalUpload/301067d397c4bf05f1c000a47f88725b/vat_transactions.csv', 'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'my-vat-data', 'description': 'My dataset as a CSV', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/2550d0cd-923a-4266-9fd3-c574cbc5929e/resourceGroups/brianombega-rg/providers/Microsoft.MachineLearningServices/workspaces/Masters_Ombega/data/my-vat-data/versions/3', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/brianombega3/code/Users/brianombega', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7ee637f34190>, 'serialize': <msrest.serialization.Serializer object at 0x7ee637f34250>, 'version': '3', 'latest_version': None, 'datastore': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1747317541528
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Sample inputs (replace or expand as needed)\n",
        "locations = ['Nairobi', 'Mombasa', 'Kisumu', 'Nakuru', 'Eldoret']\n",
        "sectors = ['Retail', 'Manufacturing', 'ICT', 'Construction', 'Wholesale Trade']\n",
        "directors = [f'DIR{str(i).zfill(3)}' for i in range(1, 101)]  # 100 synthetic directors\n",
        "\n",
        "# # Utility: Random date in a recent time window (20212024)\n",
        "# def random_registration_date(start_year=2021, end_year=2024):\n",
        "#     start = datetime(start_year, 1, 1)\n",
        "#     end = datetime(end_year, 12, 31)\n",
        "#     return fake.date_between_dates(start_date=start, end_date=end)\n",
        "\n",
        "# Utility: Deregistration date shortly after registration\n",
        "def random_deregistration_date(reg_date, min_days=30, max_days=180):\n",
        "    return reg_date + timedelta(days=random.randint(min_days, max_days))\n",
        "\n",
        "# Generate missing trader entities\n",
        "def generate_missing_traders(n_missing_traders=50):\n",
        "    traders = []\n",
        "\n",
        "    for i in range(1, n_missing_traders + 1):\n",
        "        taxpayer_id = f\"MT{str(i).zfill(4)}\"\n",
        "        owners = random.sample(directors, k=random.randint(1, 2))\n",
        "        reg_date = random_registration_date(2022, 2022)\n",
        "        dereg_date = random_deregistration_date(reg_date)\n",
        "\n",
        "        traders.append({\n",
        "            'taxpayer_id': taxpayer_id,\n",
        "            'location': random.choice(locations),\n",
        "            'economic_sector': random.choice(sectors),\n",
        "            'entity_type': 'Non-Individual',\n",
        "            'beneficial_owners': owners,\n",
        "            'registration_date': reg_date.isoformat(),\n",
        "            'deregistration_date': dereg_date.isoformat()\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(traders)\n",
        "\n",
        "# Example usage\n",
        "missing_traders_df = generate_missing_traders(50)\n",
        "print(missing_traders_df.head())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "  taxpayer_id location economic_sector     entity_type beneficial_owners  \\\n0      MT0001   Kisumu             ICT  Non-Individual          [DIR005]   \n1      MT0002  Eldoret   Manufacturing  Non-Individual          [DIR086]   \n2      MT0003  Eldoret   Manufacturing  Non-Individual          [DIR016]   \n3      MT0004   Nakuru             ICT  Non-Individual  [DIR080, DIR066]   \n4      MT0005  Eldoret             ICT  Non-Individual  [DIR065, DIR008]   \n\n     registration_date  deregistration_date  \n0  2022-02-04T00:00:00  2022-06-02T00:00:00  \n1  2022-08-18T00:00:00  2022-11-16T00:00:00  \n2  2022-11-05T00:00:00  2023-05-01T00:00:00  \n3  2022-01-09T00:00:00  2022-02-23T00:00:00  \n4  2022-01-16T00:00:00  2022-03-31T00:00:00  \n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1747319471420
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}